{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5053a6d-22b8-4884-8436-195aed14e247",
   "metadata": {},
   "source": [
    "# prepare the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4cf59c9f-bf33-4fdf-892a-c0917c2a7ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!tar czf train_data_folder.tar.gz train_data_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9940dcf1-55e8-4ef8-a970-d1a7461184d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unzip:  cannot find or open datasets/Nest_detection.zip, datasets/Nest_detection.zip.zip or datasets/Nest_detection.zip.ZIP.\n"
     ]
    }
   ],
   "source": [
    "!unzip datasets/Nest_detection.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "696ca6dc-8f68-4ffb-ac27-683276c166d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf datasets/Nest_detection/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5fd696f4-87c0-4a02-a5b6-078940ba8142",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "cannot access local variable 'child' where it is not associated with a value",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/IPython/utils/_process_posix.py:151\u001b[0m, in \u001b[0;36mProcessHandler.system\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 151\u001b[0m     child \u001b[38;5;241m=\u001b[39m \u001b[43mpexpect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspawn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m-c\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Vanilla Pexpect\u001b[39;00m\n\u001b[1;32m    152\u001b[0m flush \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mstdout\u001b[38;5;241m.\u001b[39mflush\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pexpect/pty_spawn.py:205\u001b[0m, in \u001b[0;36mspawn.__init__\u001b[0;34m(self, command, args, timeout, maxread, searchwindowsize, logfile, cwd, env, ignore_sighup, echo, preexec_fn, encoding, codec_errors, dimensions, use_poll)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 205\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_spawn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreexec_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdimensions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_poll \u001b[38;5;241m=\u001b[39m use_poll\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pexpect/pty_spawn.py:303\u001b[0m, in \u001b[0;36mspawn._spawn\u001b[0;34m(self, command, args, preexec_fn, dimensions)\u001b[0m\n\u001b[1;32m    300\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs \u001b[38;5;241m=\u001b[39m [a \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(a, \u001b[38;5;28mbytes\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m a\u001b[38;5;241m.\u001b[39mencode(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoding)\n\u001b[1;32m    301\u001b[0m                  \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs]\n\u001b[0;32m--> 303\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mptyproc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_spawnpty\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    304\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mcwd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    306\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mptyproc\u001b[38;5;241m.\u001b[39mpid\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pexpect/pty_spawn.py:315\u001b[0m, in \u001b[0;36mspawn._spawnpty\u001b[0;34m(self, args, **kwargs)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m'''Spawn a pty and return an instance of PtyProcess.'''\u001b[39;00m\n\u001b[0;32m--> 315\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mptyprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPtyProcess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspawn\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/ptyprocess/ptyprocess.py:315\u001b[0m, in \u001b[0;36mPtyProcess.spawn\u001b[0;34m(cls, argv, cwd, env, echo, preexec_fn, dimensions, pass_fds)\u001b[0m\n\u001b[1;32m    314\u001b[0m os\u001b[38;5;241m.\u001b[39mclose(exec_err_pipe_write)\n\u001b[0;32m--> 315\u001b[0m exec_err_data \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexec_err_pipe_read\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4096\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    316\u001b[0m os\u001b[38;5;241m.\u001b[39mclose(exec_err_pipe_read)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msystem\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtar -xvzf datasets/Nest_detection.tar.gz -C datasets/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/ipykernel/zmqshell.py:657\u001b[0m, in \u001b[0;36mZMQInteractiveShell.system_piped\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m    655\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_ns[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_exit_code\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m system(cmd)\n\u001b[1;32m    656\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 657\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_ns[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_exit_code\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43msystem\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvar_expand\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/IPython/utils/_process_posix.py:167\u001b[0m, in \u001b[0;36mProcessHandler.system\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m    162\u001b[0m         out_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(child\u001b[38;5;241m.\u001b[39mbefore)\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# We need to send ^C to the process.  The ascii code for '^C' is 3\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# (the character is known as ETX for 'End of Text', see\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;66;03m# curses.ascii.ETX).\u001b[39;00m\n\u001b[0;32m--> 167\u001b[0m     \u001b[43mchild\u001b[49m\u001b[38;5;241m.\u001b[39msendline(\u001b[38;5;28mchr\u001b[39m(\u001b[38;5;241m3\u001b[39m))\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;66;03m# Read and print any more output the program might produce on its\u001b[39;00m\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;66;03m# way out.\u001b[39;00m\n\u001b[1;32m    170\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: cannot access local variable 'child' where it is not associated with a value"
     ]
    }
   ],
   "source": [
    "!tar -xvzf datasets/Nest_detection.tar.gz -C datasets/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa13db9-ea17-4ebc-97e9-b06c78a70669",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# rename all labels.csv files to txt\n",
    "import os\n",
    "\n",
    "rename_path = \"datasets/Nest_detection/test/labels\"\n",
    "\n",
    "for filename in os.listdir(rename_path):\n",
    "    # Check if the file is a .csv file\n",
    "    if filename.endswith('.csv'):\n",
    "        # Construct full file path\n",
    "        csv_file = os.path.join(rename_path, filename)\n",
    "        # Construct new file name by replacing .csv with .txt\n",
    "        txt_file = os.path.join(rename_path, filename.replace('.csv', '.txt'))\n",
    "        # Rename the file\n",
    "        os.rename(csv_file, txt_file)\n",
    "\"\"\"        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215f5652-6dc6-4f05-a5c3-c68ecda1a3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import pandas as pd\n",
    "\n",
    "rename_path = \"datasets/Nest_detection/test/labels\"\n",
    "\n",
    "for filename in os.listdir(rename_path):\n",
    "    # Check if the file is a .csv file\n",
    "    if filename.endswith('.txt'):\n",
    "        label_file = os.path.join(rename_path, filename)\n",
    "        df_t = pd.read_csv(label_file, sep=\",\")\n",
    "\n",
    "        df_t.head()\n",
    "        break\n",
    "        df_t.to_csv(label_file, index=False, header=False, sep=\" \")\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9d49d6-b611-4beb-91be-561f4039c295",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e19edd5-5989-40f6-85a4-8d052f89880a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ultralytics sahi "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53666b74-2149-47aa-8ff3-25a0473cd529",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "from sahi import AutoDetectionModel\n",
    "from sahi.predict import get_sliced_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93aaa0d0-baea-4f75-9a28-4edbb3c4e267",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Load a model\n",
    "model = YOLO(\"yolov8l.pt\")  # load a pretrained model (recommended for training)\n",
    "\n",
    "# Train the model\n",
    "results = model.train(data=\"datasets/data.yaml\", epochs=50, imgsz=400, batch=128, device=[0, 1], patience=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208e126d-43b6-4377-8179-5a6e8ac3d3af",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "#### from ultralytics import YOLO\n",
    "\n",
    "model_yv8 = YOLO(\"yolov8l.pt\")\n",
    "\n",
    "# Train the model\n",
    "results = model_yv8.train(data=\"/home/jovyan/deep_forest_root/data.yaml\", epochs=500, imgsz=400, batch=30, patience=50, device=[ 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1745c4-24c5-4f27-8c58-a90e2b086496",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model_yv8 = YOLO(\"yolov8l.pt\")\n",
    "\n",
    "# Train the model\n",
    "results = model_yv8.train(data=\"/home/jovyan/deep_forest_root/data.yaml\", epochs=100, imgsz=400, batch=240, patience=50, device=[0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d245feb4-882e-426e-aa0e-00d12f4a30ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model_yv8 = YOLO(\"yolov8x.pt\")\n",
    "\n",
    "# Train the model\n",
    "results = model_yv8.train(data=\"/home/jovyan/deep_forest_root/data.yaml\", epochs=500, imgsz=400, batch=30, patience=50, device=[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f60c45a-54e5-479b-95e3-60d684a82d9e",
   "metadata": {},
   "source": [
    "## Applying Sliced Inference\n",
    "https://docs.ultralytics.com/guides/sahi-tiled-inference/#import-modules-and-download-resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a74eb6-815b-40fa-b506-b5570d29bde5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e89d077-a6e9-4d62-9662-c90e3ccabf73",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "yolov8_model_path = \"runs/detect/train24/weights/best.pt\"\n",
    "# yolov10_model_path = \"runs/detect/train16/weights/best.pt\"\n",
    "\n",
    "detection_model = AutoDetectionModel.from_pretrained(\n",
    "    model_type=\"yolov8\",\n",
    "    model_path=yolov8_model_path,\n",
    "    confidence_threshold=0.8,\n",
    "    device=\"cuda:0\",  # or 'cuda:0'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d698d044-1947-491c-95bd-245930778863",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "result = get_sliced_prediction(\n",
    "    # \"deep_forest_root/jerrod_crops/Jerrod_03_21_2022DJI_0024_20.png\",\n",
    "    # \"./deep_forest_root/JetportNew_C/JetPortNew_03_029_2022_DJI_0020.JPG\",\n",
    "    \"./deep_forest_root/jerrod/Jerrod_03_21_2022DJI_0024.JPG\",\n",
    "    detection_model,\n",
    "    slice_height=400,\n",
    "    slice_width=400,\n",
    "    overlap_height_ratio=0.1,\n",
    "    overlap_width_ratio=0.1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67c7958-b97b-49f9-9189-5c45d7d02820",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "result.export_visuals(export_dir=\"demo_data/\")\n",
    "Image(\"demo_data/prediction_visual.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1323176e-9a44-4cc4-b9c9-089322af5c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(result.object_prediction_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5d694a-defe-4661-ad7c-23e45af3e1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.object_prediction_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da63988-1875-4164-aff9-187002b9d310",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.8\n",
    "filtered_predictions = [pred for pred in result.object_prediction_list if pred.score.value >= threshold]\n",
    "# \n",
    "filtered_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c5eeb2-9ae6-4022-9c73-f6ef62635215",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.object_prediction_list = filtered_predictions\n",
    "result.export_visuals(export_dir=\"demo_data/\")\n",
    "Image(\"demo_data/prediction_visual.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4967cb-d7ae-4d35-b14c-2154ebc5ff2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO predict the ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41eabdf-cb9a-4ef3-9e72-4519e337649f",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92e02fb-dd71-416d-8454-1ecfb8fe48c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_pred = pd.DataFrame([x.bbox.to_voc_bbox() for x in filtered_predictions], columns=[\"xmin\", \"ymin\", \"xmax\", \"ymax\"])\n",
    "scores = [x.score.value for x in filtered_predictions]\n",
    "df_pred[\"image_path\"] = 'Horus_04_27_2022_DJI_0245.JPG'\n",
    "df_pred[\"label\"] = 'Nest'\n",
    "df_pred[\"score\"] = scores\n",
    "df_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd89abb-0c5d-4da7-8153-d4a4f43ee8c4",
   "metadata": {},
   "source": [
    "## A manual precision and recall check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32d3a50-8d98-42e5-9bef-e1048ecc034f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from deepforest import main\n",
    "from pathlib import Path\n",
    "\n",
    "extract_folder = Path(\"./deep_forest_root/JetportNew_C\")\n",
    "# yolov8_model_path = \"runs/detect/train20/weights/best.pt\" somehow very bad model\n",
    "yolov8_model_path = \"runs/detect/train24/weights/best.pt\"\n",
    "threshold = 0.5\n",
    "\n",
    "\n",
    "detection_model = AutoDetectionModel.from_pretrained(\n",
    "    model_type=\"yolov8\",\n",
    "    model_path=yolov8_model_path,\n",
    "    confidence_threshold=threshold,\n",
    "    device=\"cuda:0\",  # or 'cuda:0'\n",
    ")\n",
    "\n",
    "predictions = []\n",
    "\n",
    "for image_name in extract_folder.glob(\"*.JPG\"):\n",
    "    print(image_name)\n",
    "    result = get_sliced_prediction(\n",
    "        str(image_name),\n",
    "        detection_model,\n",
    "        slice_height=400,\n",
    "        slice_width=400,\n",
    "        overlap_height_ratio=0.1,\n",
    "        overlap_width_ratio=0.1,\n",
    "    )\n",
    "    \n",
    "    filtered_predictions = [pred for pred in result.object_prediction_list if pred.score.value >= threshold]\n",
    "\n",
    "    df_pred = pd.DataFrame([x.bbox.to_voc_bbox() for x in filtered_predictions], columns=[\"xmin\", \"ymin\", \"xmax\", \"ymax\"])\n",
    "    scores = [x.score.value for x in filtered_predictions]\n",
    "\n",
    "    df_pred[\"image_path\"] = image_name.name\n",
    "    df_pred[\"label\"] = 'Nest'\n",
    "    df_pred[\"score\"] = scores\n",
    "\n",
    "    predictions.append(df_pred)\n",
    "\n",
    "df_prediction_short = pd.concat(predictions, axis=0)[[\"image_path\", \"xmin\", \"ymin\", \"xmax\", \"ymax\", \"label\", \"score\"]]\n",
    "\n",
    "df_prediction_short.to_csv(\"predictions_yolo.csv\", index=False)\n",
    "df_prediction_short\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22b9527-a447-4163-b93a-f8802b38ef87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_iou(box1, box2):\n",
    "    \"\"\"\n",
    "    Calculate Intersection over Union (IoU) between two bounding boxes.\n",
    "    Each box is represented as [xmin, ymin, xmax, ymax]\n",
    "    \"\"\"\n",
    "    x1_max = max(box1[0], box2[0])\n",
    "    y1_max = max(box1[1], box2[1])\n",
    "    x2_min = min(box1[2], box2[2])\n",
    "    y2_min = min(box1[3], box2[3])\n",
    "\n",
    "    # Calculate intersection area\n",
    "    inter_width = max(0, x2_min - x1_max)\n",
    "    inter_height = max(0, y2_min - y1_max)\n",
    "    inter_area = inter_width * inter_height\n",
    "\n",
    "    # Calculate areas of both bounding boxes\n",
    "    box1_area = (box1[2] - box1[0]) * (box1[3] - box1[1])\n",
    "    box2_area = (box2[2] - box2[0]) * (box2[3] - box2[1])\n",
    "\n",
    "    # Calculate union area\n",
    "    union_area = box1_area + box2_area - inter_area\n",
    "\n",
    "    # Return IoU\n",
    "    if union_area == 0:\n",
    "        return 0\n",
    "    return inter_area / union_area\n",
    "\n",
    "def calculate_precision_recall(ground_truth_file, predictions_file, iou_threshold=0.5, score_thresh=0.95):\n",
    "    \"\"\"\n",
    "    Calculate precision and recall given ground truth and predictions CSV files.\n",
    "    \"\"\"\n",
    "    # Read both CSV files\n",
    "    ground_truth_df = pd.read_csv(ground_truth_file)\n",
    "    predictions_df = pd.read_csv(predictions_file)\n",
    "\n",
    "    predictions_df = predictions_df[predictions_df.score > score_thresh]\n",
    "    predictions_df = predictions_df[[\"image_path\", \"xmin\", \"ymin\", \"xmax\", \"ymax\", \"label\"]]\n",
    "    print(f\"length of predictions: {len(predictions_df)}\")\n",
    "    true_positives = 0\n",
    "    false_positives = 0\n",
    "    false_negatives = 0\n",
    "\n",
    "    # Loop over ground truth data by image\n",
    "    for image_path in ground_truth_df['image_path'].unique():\n",
    "        # Get ground truth and predictions for the current image\n",
    "        ground_truth_boxes = ground_truth_df[ground_truth_df['image_path'] == image_path]\n",
    "        predicted_boxes = predictions_df[predictions_df['image_path'] == image_path]\n",
    "\n",
    "        # Track matches to avoid duplicates\n",
    "        matched_ground_truth = set()\n",
    "        matched_predictions = set()\n",
    "\n",
    "        # Compare each prediction to ground truth boxes\n",
    "        for idx_pred, pred_row in predicted_boxes.iterrows():\n",
    "            pred_box = [pred_row['xmin'], pred_row['ymin'], pred_row['xmax'], pred_row['ymax']]\n",
    "            matched = False\n",
    "            for idx_gt, gt_row in ground_truth_boxes.iterrows():\n",
    "                if idx_gt in matched_ground_truth:\n",
    "                    continue\n",
    "\n",
    "                gt_box = [gt_row['xmin'], gt_row['ymin'], gt_row['xmax'], gt_row['ymax']]\n",
    "                iou = calculate_iou(pred_box, gt_box)\n",
    "\n",
    "                if iou >= iou_threshold:\n",
    "                    true_positives += 1\n",
    "                    matched_ground_truth.add(idx_gt)\n",
    "                    matched_predictions.add(idx_pred)\n",
    "                    matched = True\n",
    "                    break\n",
    "\n",
    "            if not matched:\n",
    "                false_positives += 1\n",
    "\n",
    "        # Any ground truth boxes not matched are false negatives\n",
    "        false_negatives += len(ground_truth_boxes) - len(matched_ground_truth)\n",
    "\n",
    "    # Calculate precision and recall\n",
    "    precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0\n",
    "    recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0\n",
    "\n",
    "    return precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec903e24-02c3-4b24-88ba-f56e7b9b8c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "precision, recall = calculate_precision_recall(\n",
    "    ground_truth_file=\"/home/jovyan/deep_forest_root/JetportNew_C/ground_truth.csv\", \n",
    "                           predictions_file=\"predictions_yolo.csv\", \n",
    "                           iou_threshold=0.2, score_thresh=threshold)\n",
    "\n",
    "print(f\"precision: {precision}, recall: {recall} for the score threshold of {threshold}\")\n",
    "print(f\"With a dataset which was trained on perfectly split data the precision is horrible now.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a3643b-1dd9-456e-9e53-ee5d2b67b133",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(\"/home/jovyan/deep_forest_root/JetportNew_C/ground_truth.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f627eb0-41cd-4998-8c59-cac19f77d2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(\"predictions_yolo.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f34a1e1-1b0d-477f-a5e4-a42e2c8df2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_threshs = [\n",
    "    0.4, 0.5, 0.6, 0.7,\n",
    "    0.8, 0.9, 0.95, 0.99, 0.995, 0.999, 0.9995, 0.9999, 0.99995, \n",
    "                 0.99999, \n",
    "                 0.999999,\n",
    "                 0.9999999, \n",
    "                 0.99999999, 1]\n",
    "\n",
    "for score_thresh in score_threshs:\n",
    "\n",
    "    precision, recall = calculate_precision_recall(\n",
    "    ground_truth_file=\"/home/jovyan/deep_forest_root/JetportNew_C/ground_truth.csv\", \n",
    "                           predictions_file=\"predictions_yolo.csv\", \n",
    "                           iou_threshold=0.2, score_thresh=score_thresh)\n",
    "    \n",
    "    if precision + recall == 0:\n",
    "        f1_score = 0\n",
    "    else:\n",
    "        f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "        \n",
    "    print(f\"score thresh: {score_thresh}, precision: {precision:.2f}, recall: {recall:.2f}, f1 score: {f1_score:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8177af-936c-49c9-a323-acfbfd7ff0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "root_folder = Path(\"models\")\n",
    "\n",
    "from datetime import datetime\n",
    "current_date = datetime.today().strftime('%Y-%m-%d')\n",
    "\n",
    "now = datetime.now()\n",
    "current_time = now.strftime(\"%H:%M:%S\")\n",
    "print(f\"{current_date}_{current_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfc043a-b71e-48f7-a7b0-df2c7e99ee55",
   "metadata": {},
   "outputs": [],
   "source": [
    "## on the crops\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ea520a-de88-4340-8cd8-7dda015b20b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "extract_folder = Path(\"./deep_forest_root/JetportNew_C_crops\")\n",
    "# yolov8_model_path = \"runs/detect/train20/weights/best.pt\"\n",
    "threshold = 0.4\n",
    "detection_model = AutoDetectionModel.from_pretrained(\n",
    "    model_type=\"yolov8\",\n",
    "    model_path=yolov8_model_path,\n",
    "    confidence_threshold=threshold,\n",
    "    device=\"cuda:0\",  # or 'cuda:0'\n",
    ")\n",
    "\n",
    "predictions = []\n",
    "\n",
    "for image_name in extract_folder.glob(\"*.png\"):\n",
    "    print(image_name)\n",
    "    result = get_sliced_prediction(\n",
    "        str(image_name),\n",
    "        detection_model,\n",
    "        slice_height=400,\n",
    "        slice_width=400,\n",
    "        overlap_height_ratio=0.1,\n",
    "        overlap_width_ratio=0.1,\n",
    "    )\n",
    "    \n",
    "    filtered_predictions = [pred for pred in result.object_prediction_list if pred.score.value >= threshold]\n",
    "\n",
    "    df_pred = pd.DataFrame([x.bbox.to_voc_bbox() for x in filtered_predictions], columns=[\"xmin\", \"ymin\", \"xmax\", \"ymax\"])\n",
    "    scores = [x.score.value for x in filtered_predictions]\n",
    "\n",
    "    df_pred[\"image_path\"] = image_name.name\n",
    "    df_pred[\"label\"] = 'Nest'\n",
    "    df_pred[\"score\"] = scores\n",
    "\n",
    "    predictions.append(df_pred)\n",
    "\n",
    "df_prediction_short = pd.concat(predictions, axis=0)[[\"image_path\", \"xmin\", \"ymin\", \"xmax\", \"ymax\", \"label\", \"score\"]]\n",
    "\n",
    "df_prediction_short.to_csv(extract_folder / \"predictions_yolo.csv\", index=False)\n",
    "df_prediction_short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499d9bd8-04a6-44dc-b6de-1a7471373926",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56a8d22-f5b6-49d1-9ad8-b694ec04ef01",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_threshs = [\n",
    "    0.5, 0.6, 0.7,\n",
    "    0.8, 0.9, 0.95, 0.99, 0.995, 0.999, 0.9995, 0.9999, 0.99995, \n",
    "                 0.99999, \n",
    "                 0.999999,\n",
    "                 0.9999999, \n",
    "                 0.99999999, 1]\n",
    "\n",
    "for score_thresh in score_threshs:\n",
    "\n",
    "    precision, recall = calculate_precision_recall(\n",
    "    ground_truth_file=\"/home/jovyan/deep_forest_root/JetportNew_C_crops/gt.csv\", \n",
    "                           predictions_file= extract_folder / \"predictions_yolo.csv\", \n",
    "                           iou_threshold=0.2, score_thresh=score_thresh)\n",
    "    \n",
    "    if precision + recall == 0:\n",
    "        f1_score = 0\n",
    "    else:\n",
    "        f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "        \n",
    "    print(f\"score thresh: {score_thresh}, precision: {precision:.2f}, recall: {recall:.2f}, f1 score: {f1_score:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f4819a-5d06-4ca3-9bb4-0daa4003b66d",
   "metadata": {},
   "source": [
    "## Why is YOLO so bad now??\n",
    "Lets predict on data we trained on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0dc71b-6929-4c0c-9603-208b1606fc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform validation on data\n",
    "# yolov8_model_path = \"runs/detect/train20/weights/best.pt\"\n",
    "model = YOLO(yolov8_model_path)  \n",
    "metrics = model.val(data=\"/home/jovyan/deep_forest_root/data.yaml\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715edbe4-39b4-47f6-881e-2495023f0ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.box.map)  # a list contains map50-95 of each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3dea48-e943-459a-805b-cba5d9063404",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "extract_folder = Path(\"./deep_forest_root/jerrod_crops\")\n",
    "\n",
    "threshold = 0.4\n",
    "detection_model = AutoDetectionModel.from_pretrained(\n",
    "    model_type=\"yolov8\",\n",
    "    model_path=yolov8_model_path,\n",
    "    confidence_threshold=threshold,\n",
    "    device=\"cuda:0\",  # or 'cuda:0'\n",
    ")\n",
    "\n",
    "predictions = []\n",
    "\n",
    "for image_name in extract_folder.glob(\"*.png\"):\n",
    "    print(image_name)\n",
    "    result = get_sliced_prediction(\n",
    "        str(image_name),\n",
    "        detection_model,\n",
    "        slice_height=400,\n",
    "        slice_width=400,\n",
    "        overlap_height_ratio=0.1,\n",
    "        overlap_width_ratio=0.1,\n",
    "    )\n",
    "    \n",
    "    filtered_predictions = [pred for pred in result.object_prediction_list if pred.score.value >= threshold]\n",
    "\n",
    "    df_pred = pd.DataFrame([x.bbox.to_voc_bbox() for x in filtered_predictions], columns=[\"xmin\", \"ymin\", \"xmax\", \"ymax\"])\n",
    "    scores = [x.score.value for x in filtered_predictions]\n",
    "\n",
    "    df_pred[\"image_path\"] = image_name.name\n",
    "    df_pred[\"label\"] = 'Nest'\n",
    "    df_pred[\"score\"] = scores\n",
    "\n",
    "    predictions.append(df_pred)\n",
    "\n",
    "df_prediction_short = pd.concat(predictions, axis=0)[[\"image_path\", \"xmin\", \"ymin\", \"xmax\", \"ymax\", \"label\", \"score\"]]\n",
    "\n",
    "df_prediction_short.to_csv(extract_folder / \"predictions_yolo.csv\", index=False)\n",
    "df_prediction_short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52f3a8e-cbb5-41a0-8a54-85f2e8dfaad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_threshs = [\n",
    "    0.4, 0.5, 0.6, 0.7,\n",
    "    0.8, 0.9, 0.95, 0.99, 0.995, 0.999, 0.9995, 0.9999, 0.99995, \n",
    "                 0.99999, \n",
    "                 0.999999,\n",
    "                 0.9999999, \n",
    "                 0.99999999, 1]\n",
    "\n",
    "for score_thresh in score_threshs:\n",
    "\n",
    "    precision, recall = calculate_precision_recall(\n",
    "    ground_truth_file=\"/home/jovyan/deep_forest_root/jerrod_crops/gt.csv\", \n",
    "                           predictions_file=extract_folder / \"predictions_yolo.csv\", \n",
    "                           iou_threshold=0.2, score_thresh=score_thresh)\n",
    "    \n",
    "    if precision + recall == 0:\n",
    "        f1_score = 0\n",
    "    else:\n",
    "        f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "        \n",
    "    print(f\"score thresh: {score_thresh}, precision: {precision:.4f}, recall: {recall:.4f}, f1 score: {f1_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9192a10-7b7f-4c1c-9c87-6a38eb3fefeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval_pred = pd.read_csv(\"predictions_yolo.csv\")\n",
    "df_eval_pred[df_eval_pred.image_path == \"Jerrod_03_21_2022DJI_0128_99.png\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d7897b-8b37-4ef4-9aa8-65ebb398dd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_eval_gt = pd.read_csv(\"/home/jovyan/deep_forest_root/jerrod_crops/gt.csv\")\n",
    "df_eval_gt[df_eval_gt.image_path == \"Jerrod_03_21_2022DJI_0128_99.png\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a09ae7-52ea-438b-84bd-36d8ee235ad6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
